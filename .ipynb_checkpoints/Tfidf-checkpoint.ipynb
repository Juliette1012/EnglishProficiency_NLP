{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import naive_bayes, svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURR_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Databasa Dictionary created after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'database_dictionary.pickle' is load.\n"
     ]
    }
   ],
   "source": [
    "# We load the database_dictionary created with the module preprocessing\n",
    "pickle_in = open(\"database_dictionary.pickle\", \"rb\")\n",
    "database = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "print(\"Database 'database_dictionary.pickle' is load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset, occurences of different classes of SST:\n",
      " Counter({4: 483, 5: 235, 3: 222, 6: 131, 7: 75, 8: 56, 9: 40, 2: 35, 1: 3})\n"
     ]
    }
   ],
   "source": [
    "dict_database = database.items()\n",
    "\n",
    "sst_scores = []\n",
    "for file in dict_database : \n",
    "    sst_scores.append(file[1][1])\n",
    "\n",
    "occurences = collections.Counter(sst_scores)\n",
    "print('Original dataset, occurences of different classes of SST:\\n', occurences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 9 artists>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD5CAYAAADcDXXiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAANlUlEQVR4nO3dbWxe5X3H8e9vBEpLN8KDF7EkmpEatUKTKMii6ZimjWwTD1XDC4qoNshQpryhG10rtWnfTJP2IpWmUipNSBF0CxsrIEpFBKgrAqppL2A1D6NAWtVjoSQDYihQNtRttP+98EVlEhvb8W3fN1e+H8nyOdc59rl8S/7mcHzuQ6oKSVJffmnYE5AkDZ5xl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOrVnMTkn2A68DPwPerKqJJKcCtwHjwH7g8qp6JUmA64GLgTeAP66qR9/p+59++uk1Pj5+lD+CJB2bHnnkkZeqamyubYuKe/O7VfXSrPWdwP1VtSvJzrb+eeAiYFP7+AhwQ/s8r/HxcSYnJ5cwFUlSkmfn27acyzJbgT1teQ9w6azxm2vGQ8DaJGcs4ziSpCVabNwL+HaSR5LsaGPrqur5tvwCsK4trweem/W1B9rY2yTZkWQyyeT09PRRTF2SNJ/FXpb5rao6mORXgfuSfH/2xqqqJEt6jkFV7QZ2A0xMTPgMBEkaoEWduVfVwfb5EPBN4Dzgxbcut7TPh9ruB4GNs758QxuTJK2SBeOe5KQkv/zWMvAHwJPAXmBb220bcFdb3gtclRmbgddmXb6RJK2CxVyWWQd8c+YOR9YA/1hV30ryXeD2JNuBZ4HL2/73MnMb5BQzt0JePfBZS5Le0YJxr6pngLPnGH8Z2DLHeAHXDGR2kqSj4jtUJalDxl2SOrSUd6hKSza+855VPd7+XZes6vGkUeWZuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1yLhLUoeMuyR1aNFxT3JckseS3N3Wz0zycJKpJLclOaGNv6etT7Xt4ys0d0nSPJZy5n4tsG/W+peA66rqA8ArwPY2vh14pY1f1/aTJK2iRcU9yQbgEuDGth7gAuCOtsse4NK2vLWt07ZvaftLklbJYs/cvwJ8Dvh5Wz8NeLWq3mzrB4D1bXk98BxA2/5a2/9tkuxIMplkcnp6+uhmL0ma04JxT/Ix4FBVPTLIA1fV7qqaqKqJsbGxQX5rSTrmrVnEPucDH09yMXAi8CvA9cDaJGva2fkG4GDb/yCwETiQZA1wMvDywGcuSZrXgmfuVfWFqtpQVePAFcADVfWHwIPAZW23bcBdbXlvW6dtf6CqaqCzliS9o+Xc5/554DNJppi5pn5TG78JOK2NfwbYubwpSpKWajGXZX6hqr4DfKctPwOcN8c+PwU+MYC5SZKOku9QlaQOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6pBxl6QOGXdJ6tCCcU9yYpJ/TfJvSZ5K8pdt/MwkDyeZSnJbkhPa+Hva+lTbPr7CP4Mk6TCLOXP/H+CCqjob+DBwYZLNwJeA66rqA8ArwPa2/3bglTZ+XdtPkrSKFox7zfivtnp8+yjgAuCONr4HuLQtb23rtO1bkmRQE5YkLWxR19yTHJfkceAQcB/w78CrVfVm2+UAsL4trweeA2jbXwNOm+N77kgymWRyenp6WT+EJOntFhX3qvpZVX0Y2ACcB3xouQeuqt1VNVFVE2NjY8v9dpKkWZZ0t0xVvQo8CHwUWJtkTdu0ATjYlg8CGwHa9pOBlwcxWUnS4izmbpmxJGvb8nuB3wf2MRP5y9pu24C72vLetk7b/kBV1QDnLElawJqFd+EMYE+S45j5x+D2qro7ydPArUn+CngMuKntfxPw90mmgB8DV6zAvCVJ72DBuFfVE8A5c4w/w8z198PHfwp8YiCzkyQdFd+hKkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1CHjLkkdMu6S1KE1w56AtFrGd96zasfav+uSVTuWNBfP3CWpQ8Zdkjpk3CWpQ8Zdkjpk3CWpQ94t06HVvCsEvDNEGkWeuUtSh4y7JHXIuEtSh4y7JHXIuEtShxaMe5KNSR5M8nSSp5Jc28ZPTXJfkh+2z6e08ST5apKpJE8kOXelfwhJ0tst5sz9TeCzVXUWsBm4JslZwE7g/qraBNzf1gEuAja1jx3ADQOftSTpHS0Y96p6vqoebcuvA/uA9cBWYE/bbQ9waVveCtxcMx4C1iY5Y9ATlyTNb0nX3JOMA+cADwPrqur5tukFYF1bXg88N+vLDrSxw7/XjiSTSSanp6eXOm9J0jtYdNyTvB/4BvDpqvrJ7G1VVUAt5cBVtbuqJqpqYmxsbClfKklawKLinuR4ZsJ+S1Xd2YZffOtyS/t8qI0fBDbO+vINbUyStEoWc7dMgJuAfVX15Vmb9gLb2vI24K5Z41e1u2Y2A6/NunwjSVoFi3lw2PnAlcD3kjzexr4I7AJuT7IdeBa4vG27F7gYmALeAK4e5IQlSQtbMO5V9S9A5tm8ZY79C7hmmfOSJC2D71CVpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nqkHGXpA4Zd0nq0JphT0A61ozvvGdVj7d/1yWrejyNBs/cJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDxl2SOmTcJalDC8Y9ydeSHEry5KyxU5Pcl+SH7fMpbTxJvppkKskTSc5dyclLkua2mDP3vwMuPGxsJ3B/VW0C7m/rABcBm9rHDuCGwUxTkrQUC8a9qv4Z+PFhw1uBPW15D3DprPGba8ZDwNokZwxorpKkRTraa+7rqur5tvwCsK4trweem7XfgTZ2hCQ7kkwmmZyenj7KaUiS5rLsP6hWVQF1FF+3u6omqmpibGxsudOQJM1ytHF/8a3LLe3zoTZ+ENg4a78NbUyStIqONu57gW1teRtw16zxq9pdM5uB12ZdvpEkrZIF/2cdSb4O/A5wepIDwF8Au4Dbk2wHngUub7vfC1wMTAFvAFevwJwlSQtYMO5V9cl5Nm2ZY98CrlnupCRJy+M7VCWpQ8Zdkjpk3CWpQ8Zdkjpk3CWpQwveLSOpX+M771m1Y+3fdcmqHUueuUtSl4y7JHXIuEtSh4y7JHXIuEtSh4y7JHXIuEtSh7zPXdLQreb99nBs3HPvmbskdci4S1KHjLskdci4S1KHjLskdci4S1KHvBVSkmbp5bZMz9wlqUOeuQ9QL//iS3r388xdkjpk3CWpQ8Zdkjpk3CWpQ8Zdkjpk3CWpQ8Zdkjpk3CWpQ8Zdkjpk3CWpQ8Zdkjq0InFPcmGSHySZSrJzJY4hSZrfwOOe5Djgb4CLgLOATyY5a9DHkSTNbyWeCnkeMFVVzwAkuRXYCjy9AsfySYySNIdU1WC/YXIZcGFV/UlbvxL4SFV96rD9dgA72uoHgR8MdCLvLqcDLw17EiPG1+RIviZHOtZfk1+vqrG5Ngztee5VtRvYPazjj5Ikk1U1Mex5jBJfkyP5mhzJ12R+K/EH1YPAxlnrG9qYJGmVrETcvwtsSnJmkhOAK4C9K3AcSdI8Bn5ZpqreTPIp4J+A44CvVdVTgz5OZ7w8dSRfkyP5mhzJ12QeA/+DqiRp+HyHqiR1yLhLUoeM+5Ak2ZjkwSRPJ3kqybXDntOoSHJckseS3D3suYyKJGuT3JHk+0n2JfnosOc0bEn+vP3uPJnk60lOHPacRolxH543gc9W1VnAZuAaH9PwC9cC+4Y9iRFzPfCtqvoQcDbH+OuTZD3wZ8BEVf0GMzdvXDHcWY0W4z4kVfV8VT3all9n5pd1/XBnNXxJNgCXADcOey6jIsnJwG8DNwFU1f9W1atDndRoWAO8N8ka4H3Afw55PiPFuI+AJOPAOcDDQ57KKPgK8Dng50Oexyg5E5gG/rZdrroxyUnDntQwVdVB4K+BHwHPA69V1beHO6vRYtyHLMn7gW8An66qnwx7PsOU5GPAoap6ZNhzGTFrgHOBG6rqHOC/gWP6UdpJTmHmgYRnAr8GnJTkj4Y7q9Fi3IcoyfHMhP2Wqrpz2PMZAecDH0+yH7gVuCDJPwx3SiPhAHCgqt76L7s7mIn9sez3gP+oqumq+j/gTuA3hzynkWLchyRJmLmGuq+qvjzs+YyCqvpCVW2oqnFm/jj2QFUd82djVfUC8FySD7ahLazQI7TfRX4EbE7yvva7tIVj/I/MhxvaUyHF+cCVwPeSPN7GvlhV9w5vShphfwrc0p7X9Axw9ZDnM1RV9XCSO4BHmbnz7DF8FMHb+PgBSeqQl2UkqUPGXZI6ZNwlqUPGXZI6ZNwlqUPGXZI6ZNwlqUP/D0l2L1MQSY7sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(occurences.keys(), occurences.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons une répartition gaussienne des scores. \n",
    "Les fichiers de score SST 1 notemment sont en sous-représentation : 3 seulement. \n",
    "Il faudrait faire de l'oversampling et de l'undersampling si on souhaiterait que notre modèle puisse également bien prédire ces classes de score SST comme la classe 1 et 2 et 9 par exemple.\n",
    "On peut voir que les fichiers de score SST 4 sont représentés en plus grande quantité que les autres fichiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only with score SST classes 4 5 6 et 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "dict_database = database.items()\n",
    "\n",
    "for file in dict_database :\n",
    "    sst = int(file[1][1])\n",
    "    \n",
    "    # Because Original dataset, occurences of different classes of SST :\n",
    "    # Répartition gaussienne\n",
    "    # Si prédire ces valuers importantes : undersampling, oversampling\n",
    "    # Counter({4: 483, 5: 235, 3: 222, 6: 131, 7: 75, 8: 56, 9: 40, 2: 35, 1: 3}\n",
    "    # 1763 files\n",
    "    if sst > 2 and sst < 8 :\n",
    "        # output of the TfidfVectorizer\n",
    "        y.append(file[1][1])\n",
    "        # input : all the words of the file\n",
    "        X.append(\" \".join([w for w in file[1][0]]))\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape, occurences of different classes :\n",
      " Counter({4: 483, 5: 235, 3: 222, 6: 131, 7: 75})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "occurences = collections.Counter(y)\n",
    "print('Original dataset, occurences of different classes of SST:\\n', occurences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train_tfidf :  916\n",
      "Length val_tf_idf :  230\n"
     ]
    }
   ],
   "source": [
    "# Create 2 different sets : training set (80%) and testing set (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, shuffle=True)\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer(use_idf=True)\n",
    "\n",
    "train_tfidf = vectorizer_tfidf.fit_transform(X_train).toarray()\n",
    "\n",
    "# We not refit tfidf-vectorizer because validation set use the same vectorizer with the same vocabulary shape to encode data.\n",
    "val_tf_idf = vectorizer_tfidf.transform(X_val).toarray()\n",
    "\n",
    "print(\"Length train_tfidf : \", len(train_tfidf))\n",
    "print(\"Length val_tf_idf : \", len(val_tf_idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur classifieur\n",
      " SVC(C=5, kernel='linear')\n",
      "Matrice de confusion\n",
      " [[19 25  1  0  0]\n",
      " [11 74 11  0  0]\n",
      " [ 2 29 19  1  2]\n",
      " [ 0  4 11  7  2]\n",
      " [ 0  0  0  7  5]]\n",
      "Précision, sensibilité, f-score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.59      0.42      0.49        45\n",
      "           4       0.56      0.77      0.65        96\n",
      "           5       0.45      0.36      0.40        53\n",
      "           6       0.47      0.29      0.36        24\n",
      "           7       0.56      0.42      0.48        12\n",
      "\n",
      "    accuracy                           0.54       230\n",
      "   macro avg       0.53      0.45      0.48       230\n",
      "weighted avg       0.53      0.54      0.52       230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters ={'kernel':('linear','rbf'),'C':[1,5,10,20]}\n",
    "svm_clf = svm.SVC()\n",
    "\n",
    "# !!!! Attention adapter njob à votre machine !!!!!\n",
    "grid_clf = GridSearchCV(svm_clf, parameters, n_jobs=8, cv = 2)\n",
    "grid_clf.fit(train_tfidf, y_train)\n",
    "\n",
    "y_predict = grid_clf.best_estimator_.predict(val_tf_idf)\n",
    "print(\"Meilleur classifieur\\n\", grid_clf.best_estimator_)\n",
    "print(\"Matrice de confusion\\n\", metrics.confusion_matrix(y_val, y_predict))\n",
    "print(\"Précision, sensibilité, f-score\\n\", metrics.classification_report(y_val, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_param_selection(X, y):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, n_jobs=4)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_param_selection(train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion\n",
      " [[20 24  1  0  0]\n",
      " [14 73  8  1  0]\n",
      " [ 2 28 21  1  1]\n",
      " [ 0  3 11  8  2]\n",
      " [ 0  1  0  6  5]]\n",
      "Précision, sensibilité, f-score\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.56      0.44      0.49        45\n",
      "           4       0.57      0.76      0.65        96\n",
      "           5       0.51      0.40      0.45        53\n",
      "           6       0.50      0.33      0.40        24\n",
      "           7       0.62      0.42      0.50        12\n",
      "\n",
      "    accuracy                           0.55       230\n",
      "   macro avg       0.55      0.47      0.50       230\n",
      "weighted avg       0.55      0.55      0.54       230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.SVC(C=10.0, kernel='linear', gamma=1)\n",
    "SVM.fit(train_tfidf,y_train)# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(val_tf_idf)# Use accuracy_score function to get the accuracy\n",
    "print(\"Matrice de confusion\\n\", metrics.confusion_matrix(y_val, predictions_SVM))\n",
    "print(\"Précision, sensibilité, f-score\\n\", metrics.classification_report(y_val, predictions_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
